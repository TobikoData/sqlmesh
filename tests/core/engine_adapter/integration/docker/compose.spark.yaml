# this needs to be duplicated here and in the Trino compose file because Docker
# refuses to implement support for YAMl anchors in the `include:` mechanism
# ref: https://github.com/docker/compose/issues/5621
x-hive-metastore-environments: &hive_metastore_environments
  S3_ENDPOINT: http://minio:9000
  S3_ACCESS_KEY: minio
  S3_SECRET_KEY: minio123
  S3_PATH_STYLE_ACCESS: "true"
  REGION: ""
  GOOGLE_CLOUD_KEY_FILE_PATH: ""
  AZURE_ADL_CLIENT_ID: ""
  AZURE_ADL_CREDENTIAL: ""
  AZURE_ADL_REFRESH_URL: ""
  AZURE_ABFS_STORAGE_ACCOUNT: ""
  AZURE_ABFS_ACCESS_KEY: ""
  AZURE_WASB_STORAGE_ACCOUNT: ""
  AZURE_ABFS_OAUTH: ""
  AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
  AZURE_ABFS_OAUTH_CLIENT_ID: ""
  AZURE_ABFS_OAUTH_SECRET: ""
  AZURE_ABFS_OAUTH_ENDPOINT: ""
  AZURE_WASB_ACCESS_KEY: ""

include:
  - ./_common-hive.yaml
  
services:
  spark:
    build:
      context: ./spark
    command: /opt/bitnami/spark/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:3.5.0
    ports:
      - '15000-15100:15000-15100'
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark/conf/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    depends_on:
      - spark-hive-metastore

  spark-hive-metastore:
    hostname: spark-hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore:5432/metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://spark/
      <<: *hive_metastore_environments
    depends_on:
      - metastore
