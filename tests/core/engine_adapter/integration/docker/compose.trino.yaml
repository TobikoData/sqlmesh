# this needs to be duplicated here and in the Spark compose file because Docker
# refuses to implement support for YAMl anchors in the `include:` mechanism
# ref: https://github.com/docker/compose/issues/5621
x-hive-metastore-environments: &hive_metastore_environments
  S3_ENDPOINT: http://minio:9000
  S3_ACCESS_KEY: minio
  S3_SECRET_KEY: minio123
  S3_PATH_STYLE_ACCESS: "true"
  REGION: ""
  GOOGLE_CLOUD_KEY_FILE_PATH: ""
  AZURE_ADL_CLIENT_ID: ""
  AZURE_ADL_CREDENTIAL: ""
  AZURE_ADL_REFRESH_URL: ""
  AZURE_ABFS_STORAGE_ACCOUNT: ""
  AZURE_ABFS_ACCESS_KEY: ""
  AZURE_WASB_STORAGE_ACCOUNT: ""
  AZURE_ABFS_OAUTH: ""
  AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
  AZURE_ABFS_OAUTH_CLIENT_ID: ""
  AZURE_ABFS_OAUTH_SECRET: ""
  AZURE_ABFS_OAUTH_ENDPOINT: ""
  AZURE_WASB_ACCESS_KEY: ""

include:
  - ./_common-hive.yaml

services:

  # Trino Stack
  trino:
    image: 'trinodb/trino:465'
    ports:
      - '8080:8080'
    volumes:
      - ./trino/catalog:/etc/trino/catalog
    depends_on:
      - minio
      - metastore

  trino-datalake-hive-metastore:
    image: 'starburstdata/hive:3.1.3-e.11'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore:5432/datalake_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/datalake
      <<: *hive_metastore_environments
    depends_on:
      - metastore

  trino-testing-hive-metastore:
    image: 'starburstdata/hive:3.1.3-e.11'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore:5432/testing_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/testing
      <<: *hive_metastore_environments
    depends_on:
      - metastore

  trino-datalake-iceberg-hive-metastore:
    image: 'starburstdata/hive:3.1.3-e.11'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore:5432/datalake_iceberg_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/datalake_iceberg
      <<: *hive_metastore_environments
    depends_on:
      - metastore

  trino-datalake-delta-hive-metastore:
    image: 'starburstdata/hive:3.1.3-e.11'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore:5432/datalake_delta_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/datalake_delta
      <<: *hive_metastore_environments
    depends_on:
      - metastore

  nessie:
    image: ghcr.io/projectnessie/nessie:0.102.2
    restart: on-failure
    ports:
      - '19120:19120'
    environment:
      nessie.version.store.type: JDBC2
      nessie.version.store.persist.jdbc.datasource: postgresql
      quarkus.datasource.postgresql.jdbc.url: jdbc:postgresql://metastore:5432/nessie
      quarkus.datasource.postgresql.username: hive
      quarkus.datasource.postgresql.password: hive
      nessie.catalog.default-warehouse: warehouse
      nessie.catalog.warehouses.warehouse.location: s3://nessie/warehouse
      nessie.catalog.service.s3.default-options.region: us-east-1
      nessie.catalog.service.s3.default-options.path-style-access: 'true'
      nessie.catalog.service.s3.default-options.access-key: urn:nessie-secret:quarkus:nessie.catalog.secrets.access-key
      nessie.catalog.secrets.access-key.name: minio
      nessie.catalog.secrets.access-key.secret: minio123
      nessie.catalog.service.s3.default-options.endpoint: http://minio:9000/

    depends_on:
      - metastore

