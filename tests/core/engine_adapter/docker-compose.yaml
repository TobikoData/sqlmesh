version: '3'

x-hive-metastore-environments: &hive_metastore_environments
  S3_ENDPOINT: http://minio:9000
  S3_ACCESS_KEY: minio
  S3_SECRET_KEY: minio123
  S3_PATH_STYLE_ACCESS: "true"
  REGION: ""
  GOOGLE_CLOUD_KEY_FILE_PATH: ""
  AZURE_ADL_CLIENT_ID: ""
  AZURE_ADL_CREDENTIAL: ""
  AZURE_ADL_REFRESH_URL: ""
  AZURE_ABFS_STORAGE_ACCOUNT: ""
  AZURE_ABFS_ACCESS_KEY: ""
  AZURE_WASB_STORAGE_ACCOUNT: ""
  AZURE_ABFS_OAUTH: ""
  AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
  AZURE_ABFS_OAUTH_CLIENT_ID: ""
  AZURE_ABFS_OAUTH_SECRET: ""
  AZURE_ABFS_OAUTH_ENDPOINT: ""
  AZURE_WASB_ACCESS_KEY: ""

services:
  mysql:
    image: mysql:8.1
    ports:
      - '3306:3306'
    environment:
      MYSQL_ROOT_PASSWORD: mysql
  postgres:
    image: postgres
    ports:
      - '5432:5432'
    environment:
      POSTGRES_PASSWORD: postgres
  mssql:
    image: mcr.microsoft.com/mssql/server:2022-latest
    ports:
      - '1433:1433'
    environment:
        SA_PASSWORD: 1StrongPwd@@
        ACCEPT_EULA: Y

  # Trino Stack
  trino:
    hostname: trino
    container_name: trino
    image: 'trinodb/trino:429'
    ports:
      - '8080:8080'
    volumes:
      - ./trino/catalog:/etc/trino/catalog

  trino_metastore_db:
    image: postgres
    hostname: trino_metastore_db
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    volumes:
      - ./trino/initdb.sql:/docker-entrypoint-initdb.d/initdb.sql

  trino-datalake-hive-metastore:
    hostname: trino-datalake-hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://trino_metastore_db:5432/datalake_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/datalake
      <<: *hive_metastore_environments
    depends_on:
      - trino_metastore_db

  trino-testing-hive-metastore:
    hostname: trino-testing-hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://trino_metastore_db:5432/testing_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/testing
      <<: *hive_metastore_environments
    depends_on:
      - trino_metastore_db

  trino-datalake-iceberg-hive-metastore:
    hostname: trino-datalake-iceberg-hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://trino_metastore_db:5432/datalake_iceberg_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://trino/datalake_iceberg
      <<: *hive_metastore_environments
    depends_on:
      - trino_metastore_db

  # Spark Stack
  spark:
    build:
      context: ./spark
    command: /opt/bitnami/spark/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:3.5.0
    ports:
      - '15000-15100:15000-15100'
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark/conf/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    depends_on:
      - spark-hive-metastore

  spark_metastore_db:
    image: postgres:11
    hostname: spark_metastore_db
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore

  spark-hive-metastore:
    hostname: spark-hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://spark_metastore_db:5432/metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://spark/
      <<: *hive_metastore_environments
    depends_on:
      - spark_metastore_db

  # Shared Spark/Trino S3 Storage
  minio:
    hostname: minio
    image: 'minio/minio:RELEASE.2022-05-26T05-48-41Z'
    ports:
      - '9000:9000'
      - '9001:9001'
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server /data --console-address ":9001"

  # This job will create the "spark/trino" buckets and sub paths
  mc-job:
    image: 'minio/mc:RELEASE.2022-05-09T04-08-26Z'
    entrypoint: |
      /bin/bash -c "
      sleep 5;
      /usr/bin/mc config --quiet host add myminio http://minio:9000 minio minio123;
      /usr/bin/mc mb --quiet myminio/trino/datalake;
      /usr/bin/mc mb --quiet myminio/trino/datalake_iceberg;
      /usr/bin/mc mb --quiet myminio/trino/testing;
      /usr/bin/mc mb --quiet myminio/trino/testing_iceberg;
      /usr/bin/mc mb --quiet myminio/spark/datalake;
      /usr/bin/mc mb --quiet myminio/spark/testing
      "
    depends_on:
      - minio
